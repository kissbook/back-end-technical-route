<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>激活函数 - 吻书 - 后端技术分享博客</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="张伟"><meta name=description content="1、激活函数含义 1.1、什么是激活函数？ 激活函数是人为增加的一种功能，这种功能也被称为“传递函数”，目的是为了增加函数的“非线性能力”。 1."><meta name=keywords content="Java,Go,后端技术,博客,笔记"><meta name=generator content="Hugo 0.109.0"><link rel=canonical href=https://blog.jtyoui.com/post/pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css integrity="sha256-+ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media=screen crossorigin=anonymous><meta property="og:title" content="激活函数"><meta property="og:description" content="1、激活函数含义 1.1、什么是激活函数？ 激活函数是人为增加的一种功能，这种功能也被称为“传递函数”，目的是为了增加函数的“非线性能力”。 1."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.jtyoui.com/post/pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-12-29T10:32:00+08:00"><meta property="article:modified_time" content="2022-12-29T10:32:00+08:00"><meta property="og:site_name" content="吻书 - 后端技术分享博客"><meta itemprop=name content="激活函数"><meta itemprop=description content="1、激活函数含义 1.1、什么是激活函数？ 激活函数是人为增加的一种功能，这种功能也被称为“传递函数”，目的是为了增加函数的“非线性能力”。 1."><meta itemprop=datePublished content="2022-12-29T10:32:00+08:00"><meta itemprop=dateModified content="2022-12-29T10:32:00+08:00"><meta itemprop=wordCount content="2876"><meta itemprop=keywords content="Python,Pytorch,神经网络,"><meta name=twitter:card content="summary"><meta name=twitter:title content="激活函数"><meta name=twitter:description content="1、激活函数含义 1.1、什么是激活函数？ 激活函数是人为增加的一种功能，这种功能也被称为“传递函数”，目的是为了增加函数的“非线性能力”。 1."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-G4C429E050","auto"),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>后端技术</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://blog.jtyoui.com/>主页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.jtyoui.com/post/>归档</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.jtyoui.com/tags/>标签</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.jtyoui.com/categories/>分类</a></li><li class=mobile-menu-item><div class="mobile-menu-parent mobile-menu-item-lang"><span class=mobile-submenu-open></span>
<a href=#><i class=iconfont><svg height="16" width="16" viewBox="0 0 128 128"><path d="m64.719501 1.4279814c-34.694029.0-62.8192028 28.1251726-62.8192028 62.8192016.0 34.694036 28.1251738 62.819207 62.8192028 62.819207 4.245691.0 8.392744-.42239 12.402214-1.2253-1.616124-.77296-1.792473-6.57213-.194346-9.87848 1.779059-3.68082 7.361625-13.00555 1.840404-16.134231-5.521221-3.12869-3.98755-4.53968-7.361625-8.15914-3.374083-3.61947-1.994181-4.16357-2.208492-5.09179-.736158-3.19004 3.251385-7.975096 3.435429-8.465866.184043-.490781.184043-2.331182.122689-2.883308-.06131-.552125-2.515051-2.024446-3.12852-2.085791-.613469-.06133-.920209.98154-1.77906 1.042896-.858856.06133-4.601018-2.269838-5.39853-2.883308-.797504-.61346-1.165591-2.085792-2.269828-3.190033-1.104247-1.104252-1.226945-.24539-2.944651-.920206-1.717714-.674812-7.238935-2.69926-11.471867-4.416975-4.23294-1.717714-4.601019-4.125615-4.662365-5.827954-.06131-1.702333-2.57657-4.171587-3.756227-5.950646-1.179335-1.77906-1.396914-4.232932-1.826339-3.680809-.429425.552114 2.208484 6.993538 1.77906 7.177582-.429425.184043-1.349635-1.77906-2.576572-3.374083-1.226936-1.595016 1.28829-.736159-2.637915-8.465864-3.926198-7.729705 1.226944-11.671284 1.472324-15.704806.24539-4.033514 3.312738 1.472325 1.717715-1.104238-1.595016-2.576571.122697-7.975094-1.104246-9.938197-1.226936-1.963102-8.220475 2.208492-8.220475 2.208492.184036-1.901758 6.134682-5.153142 10.428966-8.1591366 4.294277-3.005996 6.91682-.674813 10.367621.4294236 3.450803 1.104246 3.680817.736167 2.515226-.368079-1.165591-1.1042446.49077-1.6563686 3.190031-1.2269356 2.699269.429425 3.435428 3.6808086 7.545669 3.3740746 4.110242-.306735.429425.797511.981548 1.840412.552123 1.042892-.613468.920202-3.312729 2.760607-2.699262 1.840403.06131 1.840403 4.846407 5.337177 4.785055 3.496773 3.312729-2.331183 2.821952-4.907753-.490777-2.576563 3.496773-.552115 3.496773-.552115 2.944651 1.963094 2.400546.107972 4.547684.782784 2.147139.674814 7.967076 5.597286 7.967076 5.597286-7.300273 3.98755-2.699261 4.416975-1.472325 5.337178 1.226937.920202-2.515218 2.699261-2.515218 2.699261-1.53367-1.53367-1.779059.06131-2.760614.613476-.981548.552115-.06131 1.963095-.06131 1.963095-5.076415.797512-3.926198 6.13469-3.864852 7.422971.06131 1.288289-3.251385 3.251384-4.110242 5.091796-.858857 1.840405 2.208491 5.827948.613468 6.073336-1.595016.24539-3.190031-6.011991-11.778601-3.680808-2.589322.702954-8.343174 3.680808-5.275824 9.754153 3.06734 6.073336 8.15913-1.717714 9.876843-.858857 1.717714.858857-.490778 4.72371-.122691 4.785055.368079.06131 4.8464.168662 5.09179 5.398522.245388 5.229868 6.809502 4.785065 8.220482 4.907755 1.410972.12269 6.134682-3.864859 6.809502-4.048894.674815-.184034 3.374076-2.453876 9.263377.920195 5.889301 3.374089 8.895296 2.883308 10.919743 4.294285 2.02445 1.410987.61347 4.232939 2.51523 5.153134 1.90175.920217 9.50876-.306736 11.41051 2.821966 1.90176 3.1287-7.8524 18.833491-10.91974 20.551201-3.06734 1.71772-4.478321 5.64392-7.545665 8.15913-3.067349 2.51523-7.361625 5.62854-11.410522 8.03646-3.583968 2.1311-4.228845 5.949-5.825333 7.15419 28.11404-6.24545 49.13623-31.328971 49.13623-61.323497.0-34.694029-28.125171-62.8192016-62.819206-62.8192016zM79.442753 60.382331c-.858857.245389-2.637917 1.840405-6.993547-.736166-4.35563-2.576564-7.361625-2.085794-7.729705-2.515218.0.0-.368079-1.0429 1.533671-1.226937 3.905098-.378065 8.833951 3.619464 9.938196 3.680809 1.104246.06131 1.656361-1.104245 3.619464-.471631 1.963103.631953.490777 1.023755-.368079 1.269143zM58.891546 7.6853614c-.427786-.311152.354344-.669418.82058-1.288281.269103-.357613.0695-.951289.406356-1.28829.92021-.920203 5.459876-2.208485 4.572225.306734-.887321 2.515226-5.12434 2.760614-5.799161 2.269837zm10.98109 7.9750936c-1.533672-.06131-5.14381-.442837-4.478321-1.104246 2.591952-2.576563-.981548-3.312729-3.190039-3.496766-2.208485-.184043-3.128687-1.4109786-2.02444-1.5336776 1.104237-.12269 5.521213.06139 6.257379.6748206.736158.613469 4.723709 2.208485 4.969099 3.374076.24538 1.16559.0 2.147138-1.533678 2.085793zM83.184914 15.23103c-1.226943.981547-7.400887-3.521968-8.588569-4.539674-5.153134-4.4169746-7.913742-2.9446486-8.995903-3.6808086-1.082485-.736166-.696897-1.717713.959464-3.190039 1.656369-1.472325 6.318732.490778 9.017994.797512s5.827955 2.392527 5.889301 4.871925c.06131 2.4792256 2.944649 4.7595296 1.717713 5.7410846z"/></svg></i>语言</a></div><ul class=mobile-submenu-list><li><a href=https://blog.jtyoui.com/en/>English</a></li><li><a href=https://blog.jtyoui.com/><strong>中文</strong></a></li></ul></li><li class=mobile-menu-item><a id=openSearchMobile class="mobile-menu-item-link menu-item-search" href=#><i class=iconfont><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="18" height="18" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M973.81454219 973.81454219a91.78207815 91.78207815.0 01-129.80999631.0L682.0297247 811.83972101a425.48527711 425.48527711.0 01-230.35931791 68.16531768 428.3346319 428.3346319.0 11428.3346319-428.3346319A425.48527711 425.48527711.0 01811.83972101 682.0297247l162.02961656 161.97482118a91.83687354 91.83687354.0 01-.05479538 129.80999631zm-522.1441354-828.1209266a305.97679241 305.97679241.0 100 611.95358361 305.97679241 305.97679241.0 000-611.95358361z"/></svg></i></a></li></ul></nav><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE=" crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css integrity="sha256-c0uckgykQ9v5k+IqViZOZKc47Jn7KQil4/MP3ySA3F8=" crossorigin=anonymous><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><div class=modal-dialog><div class=modal-content><div id=closeSearch title=Close class=close>X</div><div class=modal-header><div class=modal-title>Search</div></div><div class=modal-body><script>(function(){var t,n="c1253cf00539a4eb0",e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src=(document.location.protocol=="https:"?"https:":"http:")+"//cse.google.com/cse.js?cx="+n,t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script><gcse:search></gcse:search></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>后端技术</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://blog.jtyoui.com/>主页</a></li><li class=menu-item><a class=menu-item-link href=https://blog.jtyoui.com/post/>归档</a></li><li class=menu-item><a class=menu-item-link href=https://blog.jtyoui.com/tags/>标签</a></li><li class=menu-item><a class=menu-item-link href=https://blog.jtyoui.com/categories/>分类</a></li><li class=menu-item><a class="menu-item-link menu-parent menu-item-lang" href=#><i class=iconfont><svg height="16" width="16" viewBox="0 0 128 128"><path d="m64.719501 1.4279814c-34.694029.0-62.8192028 28.1251726-62.8192028 62.8192016.0 34.694036 28.1251738 62.819207 62.8192028 62.819207 4.245691.0 8.392744-.42239 12.402214-1.2253-1.616124-.77296-1.792473-6.57213-.194346-9.87848 1.779059-3.68082 7.361625-13.00555 1.840404-16.134231-5.521221-3.12869-3.98755-4.53968-7.361625-8.15914-3.374083-3.61947-1.994181-4.16357-2.208492-5.09179-.736158-3.19004 3.251385-7.975096 3.435429-8.465866.184043-.490781.184043-2.331182.122689-2.883308-.06131-.552125-2.515051-2.024446-3.12852-2.085791-.613469-.06133-.920209.98154-1.77906 1.042896-.858856.06133-4.601018-2.269838-5.39853-2.883308-.797504-.61346-1.165591-2.085792-2.269828-3.190033-1.104247-1.104252-1.226945-.24539-2.944651-.920206-1.717714-.674812-7.238935-2.69926-11.471867-4.416975-4.23294-1.717714-4.601019-4.125615-4.662365-5.827954-.06131-1.702333-2.57657-4.171587-3.756227-5.950646-1.179335-1.77906-1.396914-4.232932-1.826339-3.680809-.429425.552114 2.208484 6.993538 1.77906 7.177582-.429425.184043-1.349635-1.77906-2.576572-3.374083-1.226936-1.595016 1.28829-.736159-2.637915-8.465864-3.926198-7.729705 1.226944-11.671284 1.472324-15.704806.24539-4.033514 3.312738 1.472325 1.717715-1.104238-1.595016-2.576571.122697-7.975094-1.104246-9.938197-1.226936-1.963102-8.220475 2.208492-8.220475 2.208492.184036-1.901758 6.134682-5.153142 10.428966-8.1591366 4.294277-3.005996 6.91682-.674813 10.367621.4294236 3.450803 1.104246 3.680817.736167 2.515226-.368079-1.165591-1.1042446.49077-1.6563686 3.190031-1.2269356 2.699269.429425 3.435428 3.6808086 7.545669 3.3740746 4.110242-.306735.429425.797511.981548 1.840412.552123 1.042892-.613468.920202-3.312729 2.760607-2.699262 1.840403.06131 1.840403 4.846407 5.337177 4.785055 3.496773 3.312729-2.331183 2.821952-4.907753-.490777-2.576563 3.496773-.552115 3.496773-.552115 2.944651 1.963094 2.400546.107972 4.547684.782784 2.147139.674814 7.967076 5.597286 7.967076 5.597286-7.300273 3.98755-2.699261 4.416975-1.472325 5.337178 1.226937.920202-2.515218 2.699261-2.515218 2.699261-1.53367-1.53367-1.779059.06131-2.760614.613476-.981548.552115-.06131 1.963095-.06131 1.963095-5.076415.797512-3.926198 6.13469-3.864852 7.422971.06131 1.288289-3.251385 3.251384-4.110242 5.091796-.858857 1.840405 2.208491 5.827948.613468 6.073336-1.595016.24539-3.190031-6.011991-11.778601-3.680808-2.589322.702954-8.343174 3.680808-5.275824 9.754153 3.06734 6.073336 8.15913-1.717714 9.876843-.858857 1.717714.858857-.490778 4.72371-.122691 4.785055.368079.06131 4.8464.168662 5.09179 5.398522.245388 5.229868 6.809502 4.785065 8.220482 4.907755 1.410972.12269 6.134682-3.864859 6.809502-4.048894.674815-.184034 3.374076-2.453876 9.263377.920195 5.889301 3.374089 8.895296 2.883308 10.919743 4.294285 2.02445 1.410987.61347 4.232939 2.51523 5.153134 1.90175.920217 9.50876-.306736 11.41051 2.821966 1.90176 3.1287-7.8524 18.833491-10.91974 20.551201-3.06734 1.71772-4.478321 5.64392-7.545665 8.15913-3.067349 2.51523-7.361625 5.62854-11.410522 8.03646-3.583968 2.1311-4.228845 5.949-5.825333 7.15419 28.11404-6.24545 49.13623-31.328971 49.13623-61.323497.0-34.694029-28.125171-62.8192016-62.819206-62.8192016zM79.442753 60.382331c-.858857.245389-2.637917 1.840405-6.993547-.736166-4.35563-2.576564-7.361625-2.085794-7.729705-2.515218.0.0-.368079-1.0429 1.533671-1.226937 3.905098-.378065 8.833951 3.619464 9.938196 3.680809 1.104246.06131 1.656361-1.104245 3.619464-.471631 1.963103.631953.490777 1.023755-.368079 1.269143zM58.891546 7.6853614c-.427786-.311152.354344-.669418.82058-1.288281.269103-.357613.0695-.951289.406356-1.28829.92021-.920203 5.459876-2.208485 4.572225.306734-.887321 2.515226-5.12434 2.760614-5.799161 2.269837zm10.98109 7.9750936c-1.533672-.06131-5.14381-.442837-4.478321-1.104246 2.591952-2.576563-.981548-3.312729-3.190039-3.496766-2.208485-.184043-3.128687-1.4109786-2.02444-1.5336776 1.104237-.12269 5.521213.06139 6.257379.6748206.736158.613469 4.723709 2.208485 4.969099 3.374076.24538 1.16559.0 2.147138-1.533678 2.085793zM83.184914 15.23103c-1.226943.981547-7.400887-3.521968-8.588569-4.539674-5.153134-4.4169746-7.913742-2.9446486-8.995903-3.6808086-1.082485-.736166-.696897-1.717713.959464-3.190039 1.656369-1.472325 6.318732.490778 9.017994.797512s5.827955 2.392527 5.889301 4.871925c.06131 2.4792256 2.944649 4.7595296 1.717713 5.7410846z"/></svg></i>中文</a><ul class=submenu><li><a href=https://blog.jtyoui.com/en/>English</a></li></ul></li><li class=menu-item><a id=openSearch class="menu-item-link menu-item-search" href=#><i class=iconfont><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="18" height="18" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M973.81454219 973.81454219a91.78207815 91.78207815.0 01-129.80999631.0L682.0297247 811.83972101a425.48527711 425.48527711.0 01-230.35931791 68.16531768 428.3346319 428.3346319.0 11428.3346319-428.3346319A425.48527711 425.48527711.0 01811.83972101 682.0297247l162.02961656 161.97482118a91.83687354 91.83687354.0 01-.05479538 129.80999631zm-522.1441354-828.1209266a305.97679241 305.97679241.0 100 611.95358361 305.97679241 305.97679241.0 000-611.95358361z"/></svg></i></a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight wallpaper"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>激活函数</h1><div class=post-meta><time datetime=2022-12-29 class=post-time>2022-12-29</time><div class=post-category><a href=https://blog.jtyoui.com/categories/%E7%AE%97%E6%B3%95/>算法</a></div><span class=more-meta>约 2876 字</span>
<span class=more-meta>预计阅读 6 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#11什么是激活函数>1.1、什么是激活函数？</a></li><li><a href=#12为什么要用激活函数>1.2、为什么要用激活函数？</a></li><li><a href=#13什么是线性函数>1.3、什么是线性函数</a></li></ul><ul><li><a href=#21单变量输入激活函数>2.1、单变量输入激活函数</a><ul><li><a href=#211恒等函数>2.1.1、恒等函数</a></li><li><a href=#212单位阶跃函数>2.1.2、单位阶跃函数</a></li><li><a href=#213逻辑函数>2.1.3、逻辑函数</a></li><li><a href=#214双曲正切函数>2.1.4、双曲正切函数</a></li><li><a href=#215反正切函数>2.1.5、反正切函数</a></li><li><a href=#216softsign函数>2.1.6、Softsign函数</a></li><li><a href=#217反平方根函数-isru>2.1.7、反平方根函数 (ISRU)</a></li><li><a href=#218线性整流函数-relu>2.1.8、线性整流函数 (ReLU)</a></li><li><a href=#219带泄露线性整流函数-leaky-relu>2.1.9、带泄露线性整流函数 (Leaky ReLU)</a></li><li><a href=#2110参数化线性整流函数-prelu>2.1.10、参数化线性整流函数 (PReLU)</a></li><li><a href=#2111指数线性函数-elu>2.1.11、指数线性函数 (ELU)</a></li></ul></li><li><a href=#22多变量输入激活函数>2.2、多变量输入激活函数</a><ul><li><a href=#221softmax函数>2.2.1、Softmax函数</a></li><li><a href=#222maxout函数>2.2.2、Maxout函数</a></li></ul></li></ul><ul><li><a href=#31sigmoid>3.1、sigmoid</a></li><li><a href=#32tanh214双曲正切函数>3.2、<a href=#214%E5%8F%8C%E6%9B%B2%E6%AD%A3%E5%88%87%E5%87%BD%E6%95%B0>Tanh</a></a></li><li><a href=#33relu218线性整流函数-relu>3.3、<a href=#218%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0-relu>ReLU</a></a><ul><li><a href=#331leaky-relu219带泄露线性整流函数-leaky-relu>3.3.1、<a href=#219%E5%B8%A6%E6%B3%84%E9%9C%B2%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0-leaky-relu>Leaky ReLU</a></a></li><li><a href=#34softmax221softmax函数>3.4、<a href=#221softmax%E5%87%BD%E6%95%B0>Softmax</a></a></li></ul></li><li><a href=#32结果>3.2、结果</a></li><li><a href=#33最新的激活函数>3.3、最新的激活函数</a><ul><li><a href=#switch-bsearching-for-activation-functionshttpsarxivorgabs171005941>Switch-B(<a href=https://arxiv.org/abs/1710.05941>searching for activation functions</a>)</a></li></ul></li></ul></nav></div></div><div class=post-content><h1 id=1激活函数含义>1、激活函数含义</h1><h2 id=11什么是激活函数>1.1、什么是激活函数？</h2><p>激活函数是人为增加的一种功能，这种功能也被称为“传递函数”，目的是为了增加函数的“非线性能力”。</p><h2 id=12为什么要用激活函数>1.2、为什么要用激活函数？</h2><p>如果不用激活函数，那么无论神经网络是多少层，输出都是一个“线性变化”。这种情况就是原始的“感知机”。
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.svg alt=神经网络>
如果使用了激活函数，神经元就会逼近任何的“非线性函数”。这样模型有更多的拟合能力。</p><p>下面的图表示线性分割的图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%BA%BF%E6%80%A7%E5%88%86%E5%89%B2.png alt=线性分割></p><p>实际上我们其实想要的是这样的分割线
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%88%86%E5%89%B2.png alt=img.png></p><p>【注意】如果我们不用激活函数，就单纯的想增加隐藏层，能否达到类似激活函数的效果？
答案是：否</p><p>因为增加层数，就会单纯的增加Wx+b的个数，线性函数有一个特性：两个线性相加还是等于线性函数。
所以无论多少个Wx+b都可以合并同类型。变成一个更大的W'x+b'这样的形式</p><h2 id=13什么是线性函数>1.3、什么是线性函数</h2><p>线性函数的解释：只要满足线性关系的都叫线性函数
满足两个关系：假如有这样的关系：
$$
f(x) = y
$$</p><p>$$
1、f(x_i)=y_i \ 且 \ f(x_1+x_2)=y_1+y_2
$$</p><p>$$
2、f(K*x)=K*y \ 且 \ K是一个常数
$$</p><p>满足这样的关系的函数，就叫线性函数。</p><h1 id=2激活函数的种类>2、激活函数的种类</h1><h2 id=21单变量输入激活函数>2.1、单变量输入激活函数</h2><h3 id=211恒等函数>2.1.1、恒等函数</h3><p>定义：设M为一集合，于M上的恒等函数f被定义于一具有定义域和陪域M的函数，其对任一M内的元素x，会有f(x)=x的关系。</p><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%81%92%E7%AD%89%E5%87%BD%E6%95%B0.png alt=恒等函数></p><p>原函数：
$$
f(x) =x
$$
导函数：
$$
f'(x)=1
$$</p><h3 id=212单位阶跃函数>2.1.2、单位阶跃函数</h3><p>定义：又称赫维赛德阶跃函数，通常用 H 或 θ 表记，有时也会用 u、1 或 𝟙 表记，是一个由奥利弗·亥维赛提出的阶跃函数，参数为负时值为0，参数为正时值为1。</p><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8D%95%E4%BD%8D%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0.png alt=单位阶跃函数>
原函数：</p><p>$$
f(x)=\begin{Bmatrix}
0 \ x&lt;0 \\
1 \ x\geqslant 0 \\
\end{Bmatrix}
$$</p><p>导函数：</p><p>$$
f'(x)=\begin{Bmatrix}
0 \ x\neq 0 \\
无 \ x=0 \\
\end{Bmatrix}
$$</p><h3 id=213逻辑函数>2.1.3、逻辑函数</h3><p>定义：
一种常见的S型函数，其曲线逻辑斯谛曲线是一种S型曲线</p><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0.png alt=逻辑函数></p><p>原函数：
$$
f(x)=\sigma(x) + \frac{1}{1+e^{-x}}
$$
导数
$$
f'(x) = f(x)(1-f(x))
$$</p><h3 id=214双曲正切函数>2.1.4、双曲正切函数</h3><p>定义：
双曲正弦一般计为 sinh,其在复变分析中定义为:
$$
{\displaystyle \sinh :z\mapsto {\frac {\mathrm {e} ^{z}-\mathrm {e} ^{-z}}{2}}}
$$</p><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8F%8C%E6%9B%B2%E6%AD%A3%E5%88%87%E5%87%BD%E6%95%B0.png alt=双曲正切函数></p><p>原函数：
$$
{\displaystyle f(x)=\tanh(x)={\frac {(e^{x}-e^{-x})}{(e^{x}+e^{-x})}}}
$$</p><p>导数：
$$
{\displaystyle f'(x)=1-f(x)^{2}}
$$</p><h3 id=215反正切函数>2.1.5、反正切函数</h3><p>定义：
反正切是一种反三角函数，是利用已知直角三角形的对边和邻边这两条直角边的比值求出其夹角大小的函数，是高等数学中的一种基本特殊函数。
在三角学中，反正切被定义为一个角度，也就是正切值的反函数，由于正切函数在实数上不具有一一对应的关系，所以不存在反函数，
但我们可以限制其定义域，因此，反正切是单射和满射也是可逆的，但不同于反正弦和反余弦，由于限制正切函数的定义域在
$$
{\displaystyle [-{\frac {\pi }{2}},{\frac {\pi }{2}}]}[-{\frac {\pi }{2}},{\frac {\pi }{2}}]
$$
时，其值域是全体实数，因此可得到的反函数定义域也是全体实数，而不必再进一步去限制定义域。</p><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8F%8D%E6%AD%A3%E5%88%87%E5%87%BD%E6%95%B0.png alt=反正切函数>
原函数：
$$
{\displaystyle f(x)=\tan ^{-1}(x)}
$$
导数：
$$
{\displaystyle f'(x)={\frac {1}{x^{2}+1}}}
$$</p><h3 id=216softsign函数>2.1.6、Softsign函数</h3><p>图像：</p><p><img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Softsign.png alt=Softsign></p><p>原函数：
$$
{\displaystyle f(x)={\frac {x}{1+|x|}}}
$$</p><p>导数：
$$
{\displaystyle f'(x)={\frac {1}{(1+|x|)^{2}}}}
$$</p><h3 id=217反平方根函数-isru>2.1.7、反平方根函数 (ISRU)</h3><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8F%8D%E5%B9%B3%E6%96%B9%E6%A0%B9%E5%87%BD%E6%95%B0.png alt=反平方根函数></p><p>原函数：
$$
{\displaystyle f(x)={\frac {x}{\sqrt {1+\alpha x^{2}}}}}
$$</p><p>导数：
$$
{\displaystyle f'(x)=\left({\frac {1}{\sqrt {1+\alpha x^{2}}}}\right)^{3}}
$$</p><h3 id=218线性整流函数-relu>2.1.8、线性整流函数 (ReLU)</h3><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0.png alt=线性整流函数></p><p>原函数：
$$
{\displaystyle f(x)={\begin{cases}0&{\text{for }}x&lt;0\\x&{\text{for }}x\geq 0\end{cases}}}
$$</p><p>导数：
$$
{\displaystyle f'(x)={\begin{cases}0&{\text{for }}x&lt;0\\1&{\text{for }}x\geq 0\end{cases}}}
$$</p><h3 id=219带泄露线性整流函数-leaky-relu>2.1.9、带泄露线性整流函数 (Leaky ReLU)</h3><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%B8%A6%E6%B3%84%E9%9C%B2%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0.png alt=带泄露线性整流函数></p><p>原函数：
$$
{\displaystyle f(x)={\begin{cases}0.01x&{\text{for }}x&lt;0\\x&{\text{for }}x\geq 0\end{cases}}}
$$</p><p>导数：
$$
{\displaystyle f'(x)={\begin{cases}0.01&{\text{for }}x&lt;0\\1&{\text{for }}x\geq 0\end{cases}}}
$$</p><h3 id=2110参数化线性整流函数-prelu>2.1.10、参数化线性整流函数 (PReLU)</h3><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8F%82%E6%95%B0%E5%8C%96%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0.png alt=参数化线性整流函数></p><p>原函数：
$$
{\displaystyle f(\alpha ,x)={\begin{cases}\alpha x&{\text{for }}x&lt;0\\x&{\text{for }}x\geq 0\end{cases}}}
$$</p><p>导数：
$$
{\displaystyle f'(\alpha ,x)={\begin{cases}\alpha &{\text{for }}x&lt;0\\1&{\text{for }}x\geq 0\end{cases}}}
$$</p><h3 id=2111指数线性函数-elu>2.1.11、指数线性函数 (ELU)</h3><p>图像：
<img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E6%8C%87%E6%95%B0%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0.png alt=指数线性函数></p><p>原函数：
$$
{\displaystyle f(\alpha ,x)={\begin{cases}\alpha (e^{x}-1)&{\text{for }}x&lt;0\\x&{\text{for }}x\geq 0\end{cases}}}
$$</p><p>导数：
$$
{\displaystyle f'(\alpha ,x)={\begin{cases}f(\alpha ,x)+\alpha &{\text{for }}x&lt;0\\1&{\text{for }}x\geq 0\end{cases}}}
$$</p><h2 id=22多变量输入激活函数>2.2、多变量输入激活函数</h2><h3 id=221softmax函数>2.2.1、Softmax函数</h3><p>原函数：
$$
f_{i}({\vec{x}})=\frac{e^{x_{i}}}{\sum_{j=1}^{J}e^{x_{j}}} \ 且 \ i = 1, …, J
$$</p><p>导数：
$$
{\displaystyle {\frac{\partial f_{i}({\vec{x}})}{\partial x_{j}}}=f_{i}({\vec{x}})(\delta_{ij}-f_{j}({\vec{x}}))}
$$</p><h3 id=222maxout函数>2.2.2、Maxout函数</h3><p>原函数：
$$
{\displaystyle f({\vec{x}})=\max_{i}x_{i}}
$$</p><p>导数：
$$
{\displaystyle {\frac{\partial f}{\partial x_{j}}}={\begin{cases}1&{\text{for
}}j={\underset{i}{\operatorname{argmax}}},x_{i}\\0&{\text{for }}j\neq{\underset{i}{\operatorname{argmax}}},x_
{i}\end{cases}}}
$$</p><h1 id=3选择激活函数>3、选择激活函数</h1><h2 id=31sigmoid>3.1、sigmoid</h2><p>Sigmoid函数曾被广泛应用，但由于其自身的一些缺陷，现在已经很少用了。现在已经不推荐使用了</p><h2 id=32tanh214双曲正切函数>3.2、<a href=#214%E5%8F%8C%E6%9B%B2%E6%AD%A3%E5%88%87%E5%87%BD%E6%95%B0>Tanh</a></h2><p><img src=/img/Pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/tanh%E4%B8%8Esigmoid%E6%AF%94%E8%BE%83.png alt=tanh与sigmoid比较>
tanh函数与Sigmoid函数非常相似。它实际上只是Sigmoid函数的一个放大版本。
它基本上解决了所有值符号相同的问题，而其他属性都与sigmoid函数相同。
函数具有连续性和可微性。你可以看到函数是非线性的，所以我们可以很容易地将误差进行反向传播。
所以可以使用tanh来替代Sigmoid函数。
与Sigmoid函数相比，tanh函数的梯度更陡。 使用sigmoid函数还是tanh函数取决于问题陈述中对梯度的要求。
但是tanh函数出现了Sigmoid函数类似的问题，梯度渐趋平坦，并且值非常低。</p><h2 id=33relu218线性整流函数-relu>3.3、<a href=#218%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0-relu>ReLU</a></h2><p>ReLU是近几年非常受欢迎的激活函数
ReLU是如今设计神经网络时使用最广泛的激活函数。首先，ReLU函数是非线性的，这意味着我们可以很容易地反向传播误差，并激活多个神经元。
ReLU函数优于其他激活函数的一大优点是它不会同时激活所有的神经元。这是什么意思?如果输入值是负的，ReLU函数会转换为0，
而神经元不被激活。这意味着，在一段时间内，只有少量的神经元被激活，神经网络的这种稀疏性使其变得高效且易于计算。
ReLU函数也存在着梯度为零的问题。看上图，x＜0时，梯度是零，这意味着在反向传播过程中，权重没有得到更新。这就会产生死神经元，而这些神经元永远不会被激活。</p><h3 id=331leaky-relu219带泄露线性整流函数-leaky-relu>3.3.1、<a href=#219%E5%B8%A6%E6%B3%84%E9%9C%B2%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0-leaky-relu>Leaky ReLU</a></h3><p>Leaky ReLU函数只是一个ReLU函数的改良版本。我们看到，在ReLU函数中，x &lt; 0时梯度为0，这使得该区域的神经元死亡。
为了解决这个问题， Leaky ReLU出现了。这是它的定义：
替换水平线的主要优点是去除零梯度。在这种情况下，梯度是非零的，所以该区域的神经元不会成为死神经元。
与Leaky ReLU函数类似的，还有PReLU函数，它的定义与Leaky ReLU相似。
然而， 在<a href=#2110%E5%8F%82%E6%95%B0%E5%8C%96%E7%BA%BF%E6%80%A7%E6%95%B4%E6%B5%81%E5%87%BD%E6%95%B0-prelu>PReLU</a>函数中，a也是可训练的函数。神经网络还会学习a的价值，以获得更快更好的收敛。
当Leaky ReLU函数仍然无法解决死神经元问题并且相关信息没有成功传递到下一层时，可以考虑使用PReLU函数。</p><h3 id=34softmax221softmax函数>3.4、<a href=#221softmax%E5%87%BD%E6%95%B0>Softmax</a></h3><p>softmax函数也是一种sigmoid函数，但它在处理分类问题时很方便。sigmoid函数只能处理两个类。当我们想要处理多个类时，该怎么办呢？只对单类进行“是”或“不是”的分类方式将不会有任何帮助。
softmax函数将压缩每个类在0到1之间，并除以输出总和。它实际上可以表示某个类的输入概率。
比如，我们输入[1.2,0.9,0.75]，当应用softmax函数时，得到[0.42,0.31,0.27]。现在可以用这些值来表示每个类的概率。
softmax函数最好在分类器的输出层使用。</p><h2 id=32结果>3.2、结果</h2><ul><li>用于分类器时，Sigmoid函数及其组合通常效果更好。</li><li>由于梯度消失问题，有时要避免使用sigmoid和tanh函数。</li><li>ReLU函数是一个通用的激活函数，目前在大多数情况下使用。</li><li>如果神经网络中出现死神经元，那么PReLU函数就是最好的选择。</li><li>请记住，ReLU函数只能在隐藏层中使用。</li></ul><h2 id=33最新的激活函数>3.3、最新的激活函数</h2><h3 id=switch-bsearching-for-activation-functionshttpsarxivorgabs171005941>Switch-B(<a href=https://arxiv.org/abs/1710.05941>searching for activation functions</a>)</h3><p>Swish是Google在2017年10月16号提出的一种新型激活函数,其原始公式为:
$$
f(x)=x * Sigmod(x)
$$
变形Swish-B激活函数的公式则为
$$
f(x)=x * Sigmod(b * x)
$$
其拥有不饱和,光滑,非单调性的特征,而Google在论文中的多项测试表明Swish以及Swish-B激活函数的性能即佳,
在不同的数据集上都表现出了要优于当前最佳激活函数的性能.</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>张伟</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2022-12-29</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content>原创文章，如需转载请注明文章作者和出处。谢谢！</span></p></div><div class=post-reward><input type=checkbox name=reward id=reward hidden>
<label class=reward-button for=reward>赞赏支持</label><div class=qr-code><label class=qr-code-image for=reward><img class=image src=/img/%e5%be%ae%e4%bf%a1%e8%b5%9e%e8%b5%8f.jpg>
<span>微信打赏</span></label></div></div><footer class=post-footer><div class=post-tags><a href=https://blog.jtyoui.com/tags/python/>Python</a>
<a href=https://blog.jtyoui.com/tags/pytorch/>Pytorch</a>
<a href=https://blog.jtyoui.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>神经网络</a></div><nav class=post-nav><a class=next href=/post/pytorch/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/><span class="next-text nav-default">基本数据类型</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article><div class="post bg-white"><script src=https://utteranc.es/client.js repo=kissbook/back-end-technical-route issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=jtyoui@qq.com rel="me noopener" class=iconfont title=email target=_blank><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg></a><a href=https://github.com/kissbook/back-end-technical-route rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://blog.jtyoui.com/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2022 -
2023
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>后端技术</span></span>
<span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript>window.MathJax={showProcessingMessages:!1,messageStyle:"none"}</script><script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.css integrity=sha384-BdGj8xC2eZkQaxoQ8nSLefg4AV4/AwB3Fj+8SUSo7pnKP6Eoy18liIKTPn9oBYNG crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/katex.min.js integrity=sha384-JiKN5O8x9Hhs/UE5cT5AAJqieYlOZbGT3CHws/y97o3ty4R7/O5poG9F3JoiOYw1 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.0/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{})})</script><script type=text/javascript src=/js/load-photoswipe.js></script>
<script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.js integrity="sha256-AC9ChpELidrhGHX23ZU53vmRdz3FhKaN9E28+BbcWBw=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous></script>
<script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<script>$("#openSearch, #openSearchMobile").click(function(){$(".modal-dialog").addClass("visible")}),$("#closeSearch").click(function(){$(".modal-dialog").removeClass("visible")}),$(document).click(function(e){$(e.target).closest(".modal-content, #openSearch, #openSearchMobile").length||$("body").find(".modal-dialog").removeClass("visible")})</script></body></html>